{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive MLP to detect spam\n",
    "In this file we aim to build the most basic solution that classifies emails.\n",
    "We don't expect a good solution, just something that works so that we can implement changes later on, one at a time.\n",
    "\n",
    "Naive ideas :\n",
    "- No word embedder and using the tokens created from the words as input for our classifier.\n",
    "- Classifier itself : MLP\n",
    "\n",
    "Implementation is based on https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8, and we try in this notebook to understand each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # conda install -c anaconda pandas\n",
    "\n",
    "#Deep learning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Text processing\n",
    "import tensorflow as tf # conda install -c conda-forge tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familiarizing ourselves with the Tokenizer\n",
    "A tokenizer converts a string, such as a sentence, into individual tokens. These may be words or numbers. The simplest tokenizer consists in separating a sentence into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here’s',\n",
       " 'to',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'ones,',\n",
       " 'the',\n",
       " 'misfits,',\n",
       " 'the',\n",
       " 'rebels,',\n",
       " 'the',\n",
       " 'troublemakers']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Here’s to the crazy ones, the misfits, the rebels, the troublemakers\"\n",
    "text.split() # python method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several details to take into account. For example, whether to include punctuation and how to handle upper case letters. The tokenizer method from tensorflow.keras allows us to transform text into sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 1, 4, 5, 1, 6, 1, 7, 1, 8]]\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow.keras method\n",
    "#Tokenizer can handle spaces at start of string\n",
    "text2 = [\" Here’s to the crazy ones, the misfits, the rebels, the troublemakers\"]\n",
    "        # LIST containing our string, not the same thing I don't know why\n",
    "tokenizer = Tokenizer(num_words=50, lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(text2) \n",
    "sequences = tokenizer.texts_to_sequences(text2)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine each command.\n",
    "\n",
    "*fit_on_texts* updates the vocabulary of our tokenizer. Each word is assigned an index based on how frequent it appears in our text. So the most common word gets assigned 1, the second most common 2 and so on. The index 0 is reserved for padding.\n",
    "\n",
    "We can define a limit to the size of our vocabulary, defined in the first line with *num_word=50*, which can allow us to filter out rare words. The tokenizer method filters out all punctuation by default, and *lower=True* converts all uppercase characters to lowercase. Setting *char_level=False* simply means we split at the level of words rather than at the level of characters.\n",
    "\n",
    "*texts_to_sequences* transforms the given text into a sequence of indices, using the internal vocabulary of our tokenizer. Having the two commands be separate allows us to \"train\" our vocabulary on one text and convert any new text we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'here’s': 2,\n",
       " 'to': 3,\n",
       " 'crazy': 4,\n",
       " 'ones': 5,\n",
       " 'misfits': 6,\n",
       " 'rebels': 7,\n",
       " 'troublemakers': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "Following the tutorial on https://towardsdatascience.com/nlp-spam-detection-in-sms-text-data-using-deep-learning-b8632db85cc8 to get something started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/ThinhNguyendai/SMSSpamDetection/main/SMSSpamCollection\" #Use the RAW one\n",
    "messages = pd.read_csv(url, sep ='\\t', names=[\"label\", \"message\"])\n",
    "messages[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                                            message\n",
      "103   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "154   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "207   ham  As I entered my cabin my PA said, '' Happy B'd...\n",
      "223   ham                             Sorry, I'll call later\n",
      "326   ham                   No calls..messages..missed calls\n",
      "339   ham                             Sorry, I'll call later\n",
      "357  spam  Congratulations ur awarded 500 of CD vouchers ...\n",
      "444   ham                             Sorry, I'll call later\n",
      "533   ham                  Gudnite....tc...practice going on\n",
      "655   ham                       Did u got that persons story\n"
     ]
    }
   ],
   "source": [
    "duplicatedRow = messages[messages.duplicated()]\n",
    "print(duplicatedRow[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5572 messages, 4825 of which are ham and 747 are spam. The dataset is **highly unbalanced, so we need to do something about it.**. We also have 403 duplicate messages.\n",
    "\n",
    "There are many ways to handle unbalanced dataset, and it is worth exploring other ways than the one shown in the link. The author uses downsampling, which simply deletes observations from the class that is overrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_msg = messages[messages.label =='ham']\n",
    "spam_msg = messages[messages.label=='spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(747, 2) (747, 2)\n"
     ]
    }
   ],
   "source": [
    "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 704)\n",
    "spam_msg_df = spam_msg\n",
    "print(ham_msg_df.shape, spam_msg_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Maybe?! Say hi to  and find out if  got his ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Jos ask if u wana meet up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>I dont know oh. Hopefully this month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dear Hero,i am leaving to qatar tonite for an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>No that just means you have a fat head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Maybe?! Say hi to  and find out if  got his ca...\n",
       "1      ham                         Jos ask if u wana meet up?\n",
       "2      ham              I dont know oh. Hopefully this month.\n",
       "3      ham  Dear Hero,i am leaving to qatar tonite for an ...\n",
       "4      ham             No that just means you have a fat head\n",
       "...    ...                                                ...\n",
       "1489  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "1490  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "1491  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "1492  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "1493  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_df = pd.concat([ham_msg_df, spam_msg_df])\n",
    "msg_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_labels = (msg_df['label'].map({'ham': 0, 'spam': 1})).values\n",
    "            # map creates a dataframe where we replace values\n",
    "            # .values is to extract the values as an array\n",
    "msg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "train_msg, test_msg, train_labels, test_labels = train_test_split(msg_df['message'],\n",
    "                                                                  msg_labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=705)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "299\n",
      "\n",
      "\n",
      "5039    Thanks for being there for me just to talk to ...\n",
      "1122    Do you want 750 anytime any network mins 150 t...\n",
      "1751                           Got it..mail panren paru..\n",
      "1376                              We're finally ready fyi\n",
      "3906    Do you want a new video handset? 750 anytime a...\n",
      "                              ...                        \n",
      "3562    Text BANNEDUK to 89555 to see! cost 150p texto...\n",
      "5537    Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "1952    Haha... Really oh no... How? Then will they de...\n",
      "4432       2mro i am not coming to gym machan. Goodnight.\n",
      "2808    December only! Had your mobile 11mths+? You ar...\n",
      "Name: message, Length: 1195, dtype: object\n",
      "\n",
      "\n",
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_msg))\n",
    "print(len(test_msg))\n",
    "print(\"\\n\")\n",
    "print(train_msg)\n",
    "print(\"\\n\")\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer : turn words into integers\n",
    "oov_tok = \"<OOV>\" # What to replace words that are not in the vocabulary with\n",
    "vocab_size = 500 # Maximum number of words for tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size,\n",
    "                      char_level=False, # Work words by word\n",
    "                      oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(train_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'to': 2,\n",
       " 'you': 3,\n",
       " 'a': 4,\n",
       " 'i': 5,\n",
       " 'call': 6,\n",
       " 'the': 7,\n",
       " 'your': 8,\n",
       " 'u': 9,\n",
       " 'for': 10,\n",
       " 'is': 11,\n",
       " 'now': 12,\n",
       " 'and': 13,\n",
       " '2': 14,\n",
       " 'free': 15,\n",
       " 'or': 16,\n",
       " 'on': 17,\n",
       " 'in': 18,\n",
       " 'have': 19,\n",
       " 'ur': 20,\n",
       " 'txt': 21,\n",
       " 'me': 22,\n",
       " 'from': 23,\n",
       " '4': 24,\n",
       " 'of': 25,\n",
       " 'are': 26,\n",
       " 'text': 27,\n",
       " 'with': 28,\n",
       " 'it': 29,\n",
       " 'this': 30,\n",
       " 'get': 31,\n",
       " 'mobile': 32,\n",
       " 'just': 33,\n",
       " 'stop': 34,\n",
       " 'no': 35,\n",
       " 'my': 36,\n",
       " 'only': 37,\n",
       " 'reply': 38,\n",
       " 'claim': 39,\n",
       " 'will': 40,\n",
       " 'send': 41,\n",
       " 'out': 42,\n",
       " 'so': 43,\n",
       " 'if': 44,\n",
       " 'that': 45,\n",
       " 'be': 46,\n",
       " 'we': 47,\n",
       " 'our': 48,\n",
       " 'prize': 49,\n",
       " 'www': 50,\n",
       " 'can': 51,\n",
       " 'do': 52,\n",
       " 'not': 53,\n",
       " 'at': 54,\n",
       " 'cash': 55,\n",
       " 'but': 56,\n",
       " 'won': 57,\n",
       " '150p': 58,\n",
       " 'new': 59,\n",
       " 't': 60,\n",
       " 'win': 61,\n",
       " 'msg': 62,\n",
       " '1': 63,\n",
       " 'please': 64,\n",
       " 'phone': 65,\n",
       " '50': 66,\n",
       " 'who': 67,\n",
       " 'uk': 68,\n",
       " 'week': 69,\n",
       " 'urgent': 70,\n",
       " 'go': 71,\n",
       " 'all': 72,\n",
       " 'nokia': 73,\n",
       " 'tone': 74,\n",
       " \"i'm\": 75,\n",
       " 'service': 76,\n",
       " 'when': 77,\n",
       " 'min': 78,\n",
       " 'what': 79,\n",
       " 'know': 80,\n",
       " 'want': 81,\n",
       " 'r': 82,\n",
       " 'by': 83,\n",
       " 'c': 84,\n",
       " 'up': 85,\n",
       " 'been': 86,\n",
       " 'good': 87,\n",
       " 'back': 88,\n",
       " 'contact': 89,\n",
       " 'how': 90,\n",
       " '16': 91,\n",
       " '18': 92,\n",
       " 'customer': 93,\n",
       " 'co': 94,\n",
       " 'com': 95,\n",
       " 'message': 96,\n",
       " 'per': 97,\n",
       " '£1': 98,\n",
       " 'lt': 99,\n",
       " 'gt': 100,\n",
       " 'then': 101,\n",
       " 'time': 102,\n",
       " 'guaranteed': 103,\n",
       " 'chat': 104,\n",
       " 'day': 105,\n",
       " 'its': 106,\n",
       " 'as': 107,\n",
       " 'today': 108,\n",
       " 'got': 109,\n",
       " 'see': 110,\n",
       " 'ok': 111,\n",
       " 'hi': 112,\n",
       " 'find': 113,\n",
       " '3': 114,\n",
       " 'n': 115,\n",
       " 'he': 116,\n",
       " 'every': 117,\n",
       " '£1000': 118,\n",
       " 'cs': 119,\n",
       " 'was': 120,\n",
       " 'am': 121,\n",
       " 'more': 122,\n",
       " 'love': 123,\n",
       " 'like': 124,\n",
       " 'any': 125,\n",
       " 'mins': 126,\n",
       " 'ringtone': 127,\n",
       " 'holiday': 128,\n",
       " 'has': 129,\n",
       " 'an': 130,\n",
       " 'come': 131,\n",
       " 'camera': 132,\n",
       " 'there': 133,\n",
       " 'receive': 134,\n",
       " 'draw': 135,\n",
       " 'k': 136,\n",
       " 'yes': 137,\n",
       " 'sms': 138,\n",
       " 'line': 139,\n",
       " 'live': 140,\n",
       " 'right': 141,\n",
       " 'going': 142,\n",
       " 'awarded': 143,\n",
       " 'latest': 144,\n",
       " 'one': 145,\n",
       " 'video': 146,\n",
       " 'dont': 147,\n",
       " 'they': 148,\n",
       " 'apply': 149,\n",
       " \"don't\": 150,\n",
       " 'wk': 151,\n",
       " 'about': 152,\n",
       " 'number': 153,\n",
       " 'd': 154,\n",
       " 'ü': 155,\n",
       " 'tomorrow': 156,\n",
       " 'rate': 157,\n",
       " 'tell': 158,\n",
       " 'landline': 159,\n",
       " 'code': 160,\n",
       " 'take': 161,\n",
       " 'box': 162,\n",
       " 'night': 163,\n",
       " 'da': 164,\n",
       " 'network': 165,\n",
       " 'her': 166,\n",
       " '150ppm': 167,\n",
       " 'next': 168,\n",
       " 'pls': 169,\n",
       " 'award': 170,\n",
       " 'chance': 171,\n",
       " 'shows': 172,\n",
       " 'think': 173,\n",
       " 's': 174,\n",
       " 'offer': 175,\n",
       " '000': 176,\n",
       " 'word': 177,\n",
       " 'had': 178,\n",
       " 'orange': 179,\n",
       " 'make': 180,\n",
       " 'entry': 181,\n",
       " 'po': 182,\n",
       " 'need': 183,\n",
       " 'weekly': 184,\n",
       " 'tones': 185,\n",
       " 'over': 186,\n",
       " '£100': 187,\n",
       " 'special': 188,\n",
       " '1st': 189,\n",
       " 'selected': 190,\n",
       " '5': 191,\n",
       " \"i'll\": 192,\n",
       " 'some': 193,\n",
       " 'give': 194,\n",
       " 'collection': 195,\n",
       " '£5000': 196,\n",
       " 'here': 197,\n",
       " 'thanks': 198,\n",
       " 'collect': 199,\n",
       " 'name': 200,\n",
       " 'play': 201,\n",
       " 'she': 202,\n",
       " 'later': 203,\n",
       " 'work': 204,\n",
       " '10p': 205,\n",
       " 'attempt': 206,\n",
       " 'lor': 207,\n",
       " \"it's\": 208,\n",
       " 'update': 209,\n",
       " 'mob': 210,\n",
       " 'poly': 211,\n",
       " 'sae': 212,\n",
       " '500': 213,\n",
       " 'last': 214,\n",
       " 'sorry': 215,\n",
       " 'valid': 216,\n",
       " 'account': 217,\n",
       " 'help': 218,\n",
       " 'national': 219,\n",
       " 'dear': 220,\n",
       " 'delivery': 221,\n",
       " 'yours': 222,\n",
       " '8007': 223,\n",
       " 'bonus': 224,\n",
       " 'real': 225,\n",
       " 'him': 226,\n",
       " '10': 227,\n",
       " 'opt': 228,\n",
       " '2nd': 229,\n",
       " 'why': 230,\n",
       " 'e': 231,\n",
       " 'b': 232,\n",
       " 'music': 233,\n",
       " 'club': 234,\n",
       " \"c's\": 235,\n",
       " 'colour': 236,\n",
       " 'well': 237,\n",
       " 'home': 238,\n",
       " 'top': 239,\n",
       " 'great': 240,\n",
       " 'calls': 241,\n",
       " 'still': 242,\n",
       " 'join': 243,\n",
       " 'await': 244,\n",
       " 'http': 245,\n",
       " 'cant': 246,\n",
       " '£500': 247,\n",
       " 'meet': 248,\n",
       " 'very': 249,\n",
       " '750': 250,\n",
       " 'half': 251,\n",
       " 'v': 252,\n",
       " 'keep': 253,\n",
       " 'vouchers': 254,\n",
       " '86688': 255,\n",
       " 'hot': 256,\n",
       " 'after': 257,\n",
       " 'cost': 258,\n",
       " 'first': 259,\n",
       " 'oh': 260,\n",
       " 'dating': 261,\n",
       " 'texts': 262,\n",
       " 'games': 263,\n",
       " 'should': 264,\n",
       " 'wat': 265,\n",
       " 'pounds': 266,\n",
       " 'price': 267,\n",
       " 'miss': 268,\n",
       " 'quiz': 269,\n",
       " 'which': 270,\n",
       " 'us': 271,\n",
       " 'someone': 272,\n",
       " 'life': 273,\n",
       " 'yeah': 274,\n",
       " 'waiting': 275,\n",
       " 'g': 276,\n",
       " 'pick': 277,\n",
       " 'auction': 278,\n",
       " 'row': 279,\n",
       " 'wanna': 280,\n",
       " '6': 281,\n",
       " 'too': 282,\n",
       " 'best': 283,\n",
       " 'hey': 284,\n",
       " 'sent': 285,\n",
       " 'did': 286,\n",
       " 'trying': 287,\n",
       " 'were': 288,\n",
       " 'say': 289,\n",
       " 'pic': 290,\n",
       " '£3': 291,\n",
       " 'private': 292,\n",
       " 'todays': 293,\n",
       " 'x': 294,\n",
       " '£2000': 295,\n",
       " 'order': 296,\n",
       " 'xmas': 297,\n",
       " 'end': 298,\n",
       " 'hello': 299,\n",
       " 'messages': 300,\n",
       " 'ltd': 301,\n",
       " 'gift': 302,\n",
       " 'tried': 303,\n",
       " 'services': 304,\n",
       " 'bt': 305,\n",
       " 'days': 306,\n",
       " 'anytime': 307,\n",
       " '08000930705': 308,\n",
       " 'final': 309,\n",
       " 'winner': 310,\n",
       " 'operator': 311,\n",
       " '7': 312,\n",
       " 'xxx': 313,\n",
       " 'even': 314,\n",
       " 'sexy': 315,\n",
       " 'm': 316,\n",
       " 'expires': 317,\n",
       " 'land': 318,\n",
       " 'could': 319,\n",
       " 'hope': 320,\n",
       " 'savamob': 321,\n",
       " 'content': 322,\n",
       " '£2': 323,\n",
       " 'buy': 324,\n",
       " 'already': 325,\n",
       " 'suite342': 326,\n",
       " '2lands': 327,\n",
       " 'heart': 328,\n",
       " \"i've\": 329,\n",
       " 'try': 330,\n",
       " 're': 331,\n",
       " '03': 332,\n",
       " 'off': 333,\n",
       " 'freemsg': 334,\n",
       " 'being': 335,\n",
       " 'talk': 336,\n",
       " 'ready': 337,\n",
       " 'camcorder': 338,\n",
       " 'congrats': 339,\n",
       " 'looking': 340,\n",
       " 'reveal': 341,\n",
       " 'pobox': 342,\n",
       " 'enjoy': 343,\n",
       " '12hrs': 344,\n",
       " 'his': 345,\n",
       " 'statement': 346,\n",
       " 'points': 347,\n",
       " 'identifier': 348,\n",
       " 'amp': 349,\n",
       " 'net': 350,\n",
       " 'between': 351,\n",
       " 'tc': 352,\n",
       " 'happy': 353,\n",
       " 'dogging': 354,\n",
       " 'worth': 355,\n",
       " 'offers': 356,\n",
       " 'way': 357,\n",
       " '0800': 358,\n",
       " 'where': 359,\n",
       " 'f': 360,\n",
       " 'part': 361,\n",
       " 'weekend': 362,\n",
       " 'wait': 363,\n",
       " 'sleep': 364,\n",
       " 'eg': 365,\n",
       " 'use': 366,\n",
       " 'caller': 367,\n",
       " 'charged': 368,\n",
       " 'either': 369,\n",
       " 'leave': 370,\n",
       " 'unsubscribe': 371,\n",
       " 'many': 372,\n",
       " 'rental': 373,\n",
       " 'before': 374,\n",
       " 'wkly': 375,\n",
       " 'question': 376,\n",
       " 'std': 377,\n",
       " 'mates': 378,\n",
       " 'speak': 379,\n",
       " 'info': 380,\n",
       " '£250': 381,\n",
       " 'shopping': 382,\n",
       " 'friends': 383,\n",
       " 'babe': 384,\n",
       " 'details': 385,\n",
       " 'representative': 386,\n",
       " 'ever': 387,\n",
       " 'baby': 388,\n",
       " 'girl': 389,\n",
       " 'tv': 390,\n",
       " 'complimentary': 391,\n",
       " 'place': 392,\n",
       " 'welcome': 393,\n",
       " 'important': 394,\n",
       " 'hg': 395,\n",
       " 'voucher': 396,\n",
       " 'wap': 397,\n",
       " 'money': 398,\n",
       " 'age': 399,\n",
       " 'much': 400,\n",
       " '08000839402': 401,\n",
       " 'date': 402,\n",
       " 'ac': 403,\n",
       " '£350': 404,\n",
       " 'double': 405,\n",
       " 'fun': 406,\n",
       " 'having': 407,\n",
       " 'secret': 408,\n",
       " 'admirer': 409,\n",
       " 'thinks': 410,\n",
       " 'comp': 411,\n",
       " 'may': 412,\n",
       " 'flag': 413,\n",
       " 'news': 414,\n",
       " 'answer': 415,\n",
       " 'easy': 416,\n",
       " 'late': 417,\n",
       " 'player': 418,\n",
       " 'pics': 419,\n",
       " 'direct': 420,\n",
       " 'care': 421,\n",
       " 'month': 422,\n",
       " 'mobiles': 423,\n",
       " 'haha': 424,\n",
       " \"there's\": 425,\n",
       " 'cos': 426,\n",
       " '00': 427,\n",
       " 'sub': 428,\n",
       " 'okay': 429,\n",
       " 'del': 430,\n",
       " 'pm': 431,\n",
       " 'choose': 432,\n",
       " 'txts': 433,\n",
       " 'msgs': 434,\n",
       " 'wish': 435,\n",
       " 'phones': 436,\n",
       " 'other': 437,\n",
       " 'coming': 438,\n",
       " 'fancy': 439,\n",
       " 'sex': 440,\n",
       " 'them': 441,\n",
       " 'let': 442,\n",
       " 'ipod': 443,\n",
       " 'congratulations': 444,\n",
       " '11': 445,\n",
       " 'balance': 446,\n",
       " 'mobileupd8': 447,\n",
       " 'im': 448,\n",
       " '£200': 449,\n",
       " 'yo': 450,\n",
       " 'morning': 451,\n",
       " '100': 452,\n",
       " 'told': 453,\n",
       " 'o': 454,\n",
       " 'charity': 455,\n",
       " '150': 456,\n",
       " 'pass': 457,\n",
       " 'england': 458,\n",
       " 'inc': 459,\n",
       " 'custcare': 460,\n",
       " 'rates': 461,\n",
       " 'something': 462,\n",
       " 'minutes': 463,\n",
       " \"you're\": 464,\n",
       " 'found': 465,\n",
       " '2003': 466,\n",
       " '800': 467,\n",
       " '04': 468,\n",
       " 'man': 469,\n",
       " 'charge': 470,\n",
       " 'really': 471,\n",
       " '2004': 472,\n",
       " 'because': 473,\n",
       " 'kiss': 474,\n",
       " 'ask': 475,\n",
       " '£150': 476,\n",
       " 'discount': 477,\n",
       " 'valued': 478,\n",
       " 'guess': 479,\n",
       " 'done': 480,\n",
       " 'reward': 481,\n",
       " 'lucky': 482,\n",
       " '20p': 483,\n",
       " 'ntt': 484,\n",
       " 'tonight': 485,\n",
       " 'hear': 486,\n",
       " 'years': 487,\n",
       " 'gr8': 488,\n",
       " 'address': 489,\n",
       " 'getting': 490,\n",
       " 'start': 491,\n",
       " 'reach': 492,\n",
       " 'wid': 493,\n",
       " 'currently': 494,\n",
       " 'w1j6hl': 495,\n",
       " 'call2optout': 496,\n",
       " 'within': 497,\n",
       " 'nice': 498,\n",
       " '87066': 499,\n",
       " 'numbers': 500,\n",
       " 'eve': 501,\n",
       " 'sure': 502,\n",
       " 'friend': 503,\n",
       " 'polys': 504,\n",
       " 'away': 505,\n",
       " 'rcvd': 506,\n",
       " 'saturday': 507,\n",
       " 'etc': 508,\n",
       " 'bx420': 509,\n",
       " 'ip4': 510,\n",
       " '5we': 511,\n",
       " 'maybe': 512,\n",
       " 'problem': 513,\n",
       " 'txting': 514,\n",
       " 'game': 515,\n",
       " 'specially': 516,\n",
       " 'ill': 517,\n",
       " 'true': 518,\n",
       " 'hmv': 519,\n",
       " 'weeks': 520,\n",
       " 'anyway': 521,\n",
       " 'sweet': 522,\n",
       " 'sony': 523,\n",
       " 'dvd': 524,\n",
       " '82277': 525,\n",
       " 'sp': 526,\n",
       " '50p': 527,\n",
       " 'into': 528,\n",
       " 'feel': 529,\n",
       " 'always': 530,\n",
       " 'card': 531,\n",
       " 'st': 532,\n",
       " 'un': 533,\n",
       " 'redeemed': 534,\n",
       " '£800': 535,\n",
       " 'lol': 536,\n",
       " 'better': 537,\n",
       " 'yr': 538,\n",
       " 'must': 539,\n",
       " 'biz': 540,\n",
       " 'book': 541,\n",
       " 'people': 542,\n",
       " 'guys': 543,\n",
       " 'bored': 544,\n",
       " 'leh': 545,\n",
       " 'dat': 546,\n",
       " 'soon': 547,\n",
       " 'costa': 548,\n",
       " 'sol': 549,\n",
       " 'sk38xh': 550,\n",
       " \"uk's\": 551,\n",
       " '£10': 552,\n",
       " 'summer': 553,\n",
       " 'credit': 554,\n",
       " 'bid': 555,\n",
       " 'terms': 556,\n",
       " 'log': 557,\n",
       " '0870': 558,\n",
       " 'unlimited': 559,\n",
       " 'shit': 560,\n",
       " 'freephone': 561,\n",
       " 'said': 562,\n",
       " 'went': 563,\n",
       " 'ans': 564,\n",
       " 'loyalty': 565,\n",
       " 'meeting': 566,\n",
       " 'wont': 567,\n",
       " 'would': 568,\n",
       " 'food': 569,\n",
       " 'thought': 570,\n",
       " '02': 571,\n",
       " '06': 572,\n",
       " 'luv': 573,\n",
       " 'ending': 574,\n",
       " 'doing': 575,\n",
       " 'thats': 576,\n",
       " 'age16': 577,\n",
       " 'calling': 578,\n",
       " 'song': 579,\n",
       " 'each': 580,\n",
       " '11mths': 581,\n",
       " 'again': 582,\n",
       " '20': 583,\n",
       " 'motorola': 584,\n",
       " 'gay': 585,\n",
       " '08712460324': 586,\n",
       " '87077': 587,\n",
       " 'big': 588,\n",
       " 'handset': 589,\n",
       " 'year': 590,\n",
       " 'getzed': 591,\n",
       " 'flights': 592,\n",
       " 'spree': 593,\n",
       " 'shop': 594,\n",
       " \"t's\": 595,\n",
       " 'things': 596,\n",
       " 'called': 597,\n",
       " 'sunshine': 598,\n",
       " 'ringtones': 599,\n",
       " 'eat': 600,\n",
       " 'while': 601,\n",
       " 'left': 602,\n",
       " 'also': 603,\n",
       " 'weekends': 604,\n",
       " 'tot': 605,\n",
       " 'awesome': 606,\n",
       " 'boy': 607,\n",
       " 'standard': 608,\n",
       " 'forget': 609,\n",
       " '10am': 610,\n",
       " 'txtauction': 611,\n",
       " '£900': 612,\n",
       " 'yesterday': 613,\n",
       " 'area': 614,\n",
       " 'abt': 615,\n",
       " '85023': 616,\n",
       " 'unsub': 617,\n",
       " '09050090044': 618,\n",
       " 'toclaim': 619,\n",
       " 'pobox334': 620,\n",
       " 'stockport': 621,\n",
       " 'cost£1': 622,\n",
       " 'max10mins': 623,\n",
       " 'cheap': 624,\n",
       " 'company': 625,\n",
       " 'o2': 626,\n",
       " \"you've\": 627,\n",
       " 'world': 628,\n",
       " 'visit': 629,\n",
       " 'information': 630,\n",
       " 'user': 631,\n",
       " 'onto': 632,\n",
       " 'fantastic': 633,\n",
       " '1327': 634,\n",
       " 'croydon': 635,\n",
       " 'cr9': 636,\n",
       " '5wb': 637,\n",
       " 'entitled': 638,\n",
       " 'remove': 639,\n",
       " 'stuff': 640,\n",
       " 'minute': 641,\n",
       " 'bus': 642,\n",
       " 'takes': 643,\n",
       " 'entered': 644,\n",
       " 'person': 645,\n",
       " 'might': 646,\n",
       " 'crazy': 647,\n",
       " 'ts': 648,\n",
       " 'arrive': 649,\n",
       " 'maximize': 650,\n",
       " 'digital': 651,\n",
       " '28': 652,\n",
       " 'red': 653,\n",
       " 'working': 654,\n",
       " 'sky': 655,\n",
       " 'ldew': 656,\n",
       " 'down': 657,\n",
       " 'match': 658,\n",
       " '08712300220': 659,\n",
       " '08718720201': 660,\n",
       " 'll': 661,\n",
       " 'princess': 662,\n",
       " 'these': 663,\n",
       " 'store': 664,\n",
       " 'nothing': 665,\n",
       " 'rply': 666,\n",
       " 'sat': 667,\n",
       " 'enter': 668,\n",
       " 'never': 669,\n",
       " 'ldn': 670,\n",
       " 'b4': 671,\n",
       " 'local': 672,\n",
       " 'another': 673,\n",
       " 'long': 674,\n",
       " 'early': 675,\n",
       " 'logo': 676,\n",
       " 'ring': 677,\n",
       " 'mail': 678,\n",
       " 'finally': 679,\n",
       " '150pm': 680,\n",
       " 'woke': 681,\n",
       " 'cup': 682,\n",
       " 'official': 683,\n",
       " 'aight': 684,\n",
       " 'tenerife': 685,\n",
       " 'questions': 686,\n",
       " 'p': 687,\n",
       " 'few': 688,\n",
       " 'job': 689,\n",
       " 'didnt': 690,\n",
       " 'valentines': 691,\n",
       " 'hair': 692,\n",
       " 'liao': 693,\n",
       " 'asked': 694,\n",
       " 'fine': 695,\n",
       " 'pobox84': 696,\n",
       " 'fuck': 697,\n",
       " 'click': 698,\n",
       " 'awaiting': 699,\n",
       " 'wow': 700,\n",
       " 'sea': 701,\n",
       " 'yourself': 702,\n",
       " 'once': 703,\n",
       " 'watching': 704,\n",
       " 'driving': 705,\n",
       " 'member': 706,\n",
       " 'trip': 707,\n",
       " 'dis': 708,\n",
       " 'room': 709,\n",
       " 'hard': 710,\n",
       " 'computer': 711,\n",
       " \"won't\": 712,\n",
       " 'mind': 713,\n",
       " '80488': 714,\n",
       " 'knw': 715,\n",
       " '12': 716,\n",
       " 'hours': 717,\n",
       " 'does': 718,\n",
       " 'locations': 719,\n",
       " 'ec2a': 720,\n",
       " 'urawinner': 721,\n",
       " 'surprise': 722,\n",
       " 'break': 723,\n",
       " 'okie': 724,\n",
       " 'fantasies': 725,\n",
       " '08707509020': 726,\n",
       " 'records': 727,\n",
       " '86021': 728,\n",
       " 'access': 729,\n",
       " 'yet': 730,\n",
       " 'wants': 731,\n",
       " 'correct': 732,\n",
       " 'press': 733,\n",
       " 'ends': 734,\n",
       " 'contacted': 735,\n",
       " 'cum': 736,\n",
       " 'look': 737,\n",
       " 'cancel': 738,\n",
       " 'test': 739,\n",
       " 'forgot': 740,\n",
       " 'tmr': 741,\n",
       " 'oso': 742,\n",
       " 'asap': 743,\n",
       " 'months': 744,\n",
       " \"how's\": 745,\n",
       " '3g': 746,\n",
       " 'videophones': 747,\n",
       " 'videochat': 748,\n",
       " 'java': 749,\n",
       " 'dload': 750,\n",
       " 'noline': 751,\n",
       " 'rentl': 752,\n",
       " 'reference': 753,\n",
       " 'cc': 754,\n",
       " 'words': 755,\n",
       " 'pound': 756,\n",
       " 'cd': 757,\n",
       " 'id': 758,\n",
       " 'voda': 759,\n",
       " 'quoting': 760,\n",
       " 'den': 761,\n",
       " 'decimal': 762,\n",
       " 'wife': 763,\n",
       " 'sir': 764,\n",
       " 'actually': 765,\n",
       " 'though': 766,\n",
       " 'around': 767,\n",
       " 'show': 768,\n",
       " 'frnd': 769,\n",
       " '62468': 770,\n",
       " '25p': 771,\n",
       " '3030': 772,\n",
       " 'till': 773,\n",
       " 'missed': 774,\n",
       " 'plz': 775,\n",
       " 'bluetooth': 776,\n",
       " 'made': 777,\n",
       " 'pobox36504w45wq': 778,\n",
       " 'lar': 779,\n",
       " 'matches': 780,\n",
       " 'polyphonic': 781,\n",
       " 'hl': 782,\n",
       " 'partner': 783,\n",
       " 'simple': 784,\n",
       " 'zed': 785,\n",
       " 'wake': 786,\n",
       " 'lost': 787,\n",
       " 'plus': 788,\n",
       " 'until': 789,\n",
       " 'fa': 790,\n",
       " 'tkts': 791,\n",
       " '87121': 792,\n",
       " 'no1': 793,\n",
       " 'yer': 794,\n",
       " '84199': 795,\n",
       " 'eng': 796,\n",
       " 'box39822': 797,\n",
       " 'w111wx': 798,\n",
       " 'notice': 799,\n",
       " '5000': 800,\n",
       " 'tcs': 801,\n",
       " 'cw25wx': 802,\n",
       " 'na': 803,\n",
       " '1x150p': 804,\n",
       " 'car': 805,\n",
       " 'dad': 806,\n",
       " 'gonna': 807,\n",
       " 'plans': 808,\n",
       " 'little': 809,\n",
       " 'q': 810,\n",
       " 'country': 811,\n",
       " 'ansr': 812,\n",
       " 'tyrone': 813,\n",
       " 'fone': 814,\n",
       " 'write': 815,\n",
       " 'porn': 816,\n",
       " \"i'd\": 817,\n",
       " 'else': 818,\n",
       " 'plan': 819,\n",
       " 'put': 820,\n",
       " 'jordan': 821,\n",
       " '24': 822,\n",
       " 'recd': 823,\n",
       " 'cust': 824,\n",
       " 'old': 825,\n",
       " 'activate': 826,\n",
       " 'head': 827,\n",
       " 'smile': 828,\n",
       " '7pm': 829,\n",
       " '2optout': 830,\n",
       " 'wondering': 831,\n",
       " 'across': 832,\n",
       " 'evening': 833,\n",
       " 'probably': 834,\n",
       " 'nope': 835,\n",
       " 'hows': 836,\n",
       " \"didn't\": 837,\n",
       " '60p': 838,\n",
       " 'selection': 839,\n",
       " 'picked': 840,\n",
       " 'ppm': 841,\n",
       " 'action': 842,\n",
       " 'euro2004': 843,\n",
       " 'bed': 844,\n",
       " 'bank': 845,\n",
       " 'laid': 846,\n",
       " 'largest': 847,\n",
       " 'replying': 848,\n",
       " 'subscriber': 849,\n",
       " 'party': 850,\n",
       " \"doesn't\": 851,\n",
       " 'same': 852,\n",
       " 'extra': 853,\n",
       " 'tho': 854,\n",
       " 'brand': 855,\n",
       " '7250i': 856,\n",
       " 'w1jhl': 857,\n",
       " '0808': 858,\n",
       " '145': 859,\n",
       " '4742': 860,\n",
       " '9am': 861,\n",
       " '11pm': 862,\n",
       " 'stay': 863,\n",
       " 'anything': 864,\n",
       " 'registered': 865,\n",
       " 'receipt': 866,\n",
       " '80062': 867,\n",
       " 'arcade': 868,\n",
       " '434': 869,\n",
       " 'link': 870,\n",
       " 'college': 871,\n",
       " 'xx': 872,\n",
       " 'super': 873,\n",
       " 'check': 874,\n",
       " 'bloomberg': 875,\n",
       " 'dun': 876,\n",
       " 'girls': 877,\n",
       " 'horny': 878,\n",
       " 'til': 879,\n",
       " 'nite': 880,\n",
       " 'sch': 881,\n",
       " '81151': 882,\n",
       " '4t': 883,\n",
       " 'alone': 884,\n",
       " '40gb': 885,\n",
       " 'pod': 886,\n",
       " \"week's\": 887,\n",
       " 'competition': 888,\n",
       " 'wan': 889,\n",
       " 'loan': 890,\n",
       " 'purpose': 891,\n",
       " 'tenants': 892,\n",
       " 'post': 893,\n",
       " 'afternoon': 894,\n",
       " 'birthday': 895,\n",
       " 'mp3': 896,\n",
       " '83355': 897,\n",
       " 'pc': 898,\n",
       " 'listen': 899,\n",
       " 'than': 900,\n",
       " 'sipix': 901,\n",
       " '09061221066': 902,\n",
       " 'fromm': 903,\n",
       " 'ones': 904,\n",
       " 'contract': 905,\n",
       " 'house': 906,\n",
       " 'pix': 907,\n",
       " '8552': 908,\n",
       " 'vodafone': 909,\n",
       " 'fantasy': 910,\n",
       " 'dream': 911,\n",
       " 'team': 912,\n",
       " 'chennai': 913,\n",
       " 'app': 914,\n",
       " 'friday': 915,\n",
       " 'tncs': 916,\n",
       " 'read': 917,\n",
       " 'announcement': 918,\n",
       " 'vip': 919,\n",
       " 'tickets': 920,\n",
       " 'finish': 921,\n",
       " 'sport': 922,\n",
       " 'hand': 923,\n",
       " 'king': 924,\n",
       " 'credits': 925,\n",
       " 'don': 926,\n",
       " 'happen': 927,\n",
       " '88039': 928,\n",
       " 'skilgme': 929,\n",
       " \"he's\": 930,\n",
       " 'tariffs': 931,\n",
       " 'office': 932,\n",
       " 'children': 933,\n",
       " 'lonely': 934,\n",
       " 'anyone': 935,\n",
       " 'inviting': 936,\n",
       " 'paris': 937,\n",
       " 'wana': 938,\n",
       " 'bahamas': 939,\n",
       " '83600': 940,\n",
       " 'sale': 941,\n",
       " 'subscription': 942,\n",
       " '£4': 943,\n",
       " 'calls£1': 944,\n",
       " 'vary': 945,\n",
       " 'dunno': 946,\n",
       " 'juz': 947,\n",
       " '4u': 948,\n",
       " 'w': 949,\n",
       " 'thk': 950,\n",
       " 'tel': 951,\n",
       " 'eerie': 952,\n",
       " 'title': 953,\n",
       " 'set': 954,\n",
       " 'town': 955,\n",
       " 'singles': 956,\n",
       " 'high': 957,\n",
       " 'luck': 958,\n",
       " \"let's\": 959,\n",
       " 'drive': 960,\n",
       " 'moby': 961,\n",
       " '87131': 962,\n",
       " 'jus': 963,\n",
       " 'txtin': 964,\n",
       " '4info': 965,\n",
       " '786': 966,\n",
       " 'unredeemed': 967,\n",
       " '05': 968,\n",
       " 'london': 969,\n",
       " 'busy': 970,\n",
       " '2nite': 971,\n",
       " 'email': 972,\n",
       " 'girlfrnd': 973,\n",
       " 'comuk': 974,\n",
       " 'jamster': 975,\n",
       " 'é': 976,\n",
       " 'knew': 977,\n",
       " 'ref': 978,\n",
       " '250': 979,\n",
       " 'ho': 980,\n",
       " 'santa': 981,\n",
       " 'spook': 982,\n",
       " 'five': 983,\n",
       " 'cinema': 984,\n",
       " '09061209465': 985,\n",
       " 'suprman': 986,\n",
       " 'matrix3': 987,\n",
       " 'starwars3': 988,\n",
       " '2005': 989,\n",
       " '36504': 990,\n",
       " 'optout': 991,\n",
       " 'issues': 992,\n",
       " '08715705022': 993,\n",
       " 'able': 994,\n",
       " 'voicemail': 995,\n",
       " 'ya': 996,\n",
       " 'needs': 997,\n",
       " 'liverpool': 998,\n",
       " 'played': 999,\n",
       " 'original': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index) # Importance of setting a max size of vocabulary here : many rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing and padding on training and testing \n",
    "max_len = 50 # Max number of tokens, used with truncating and padding\n",
    "trunc_type = \"post\" # Truncates sequences of tokens that are longer than max_len, post=right side\n",
    "padding_type = \"post\" # Pads AFTER (with post) if sequence is shorter than max_len\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(train_msg)\n",
    "training_padded = pad_sequences (training_sequences, maxlen = max_len,\n",
    "                                 padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(test_msg)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen = max_len,\n",
    "                               padding = padding_type, truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training tensor:  (1195, 50)\n",
      "Shape of testing tensor:  (299, 50)\n"
     ]
    }
   ],
   "source": [
    "# Shape of train tensor\n",
    "print('Shape of training tensor: ', training_padded.shape)\n",
    "print('Shape of testing tensor: ', testing_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Need to convert to torch tensors to feed into neural network\n",
    "print(type(training_padded))\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(training_padded).float()\n",
    "X_test = torch.from_numpy(testing_padded).float()\n",
    "Y_train = torch.from_numpy(train_labels).float()\n",
    "Y_test = torch.from_numpy(test_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len # Number of input neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 done\n",
      "Training accuracy is equal to 0.5255230069160461\n",
      "Test accuracy is equal to 0.45819397993311034\n",
      "Sensitivity is equal to 0.013157894736842105\n",
      "Specificity is equal to 0.9183673469387755\n",
      "Iteration 2 done\n",
      "Training accuracy is equal to 0.47531381249427795\n",
      "Test accuracy is equal to 0.45484949832775917\n",
      "Sensitivity is equal to 0.1513157894736842\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 3 done\n",
      "Training accuracy is equal to 0.5280334949493408\n",
      "Test accuracy is equal to 0.6020066889632107\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.3129251700680272\n",
      "Iteration 4 done\n",
      "Training accuracy is equal to 0.6393305659294128\n",
      "Test accuracy is equal to 0.5585284280936454\n",
      "Sensitivity is equal to 0.9671052631578947\n",
      "Specificity is equal to 0.1360544217687075\n",
      "Iteration 5 done\n",
      "Training accuracy is equal to 0.5966527462005615\n",
      "Test accuracy is equal to 0.5752508361204013\n",
      "Sensitivity is equal to 0.9736842105263158\n",
      "Specificity is equal to 0.16326530612244897\n",
      "Iteration 6 done\n",
      "Training accuracy is equal to 0.5933054685592651\n",
      "Test accuracy is equal to 0.6153846153846154\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.3877551020408163\n",
      "Iteration 7 done\n",
      "Training accuracy is equal to 0.6242677569389343\n",
      "Test accuracy is equal to 0.5183946488294314\n",
      "Sensitivity is equal to 0.4144736842105263\n",
      "Specificity is equal to 0.6258503401360545\n",
      "Iteration 8 done\n",
      "Training accuracy is equal to 0.5673640370368958\n",
      "Test accuracy is equal to 0.5117056856187291\n",
      "Sensitivity is equal to 0.32894736842105265\n",
      "Specificity is equal to 0.7006802721088435\n",
      "Iteration 9 done\n",
      "Training accuracy is equal to 0.5623431205749512\n",
      "Test accuracy is equal to 0.5652173913043478\n",
      "Sensitivity is equal to 0.4276315789473684\n",
      "Specificity is equal to 0.7074829931972789\n",
      "Iteration 10 done\n",
      "Training accuracy is equal to 0.6066945791244507\n",
      "Test accuracy is equal to 0.6889632107023411\n",
      "Sensitivity is equal to 0.743421052631579\n",
      "Specificity is equal to 0.6326530612244898\n",
      "Iteration 11 done\n",
      "Training accuracy is equal to 0.6811715364456177\n",
      "Test accuracy is equal to 0.7324414715719063\n",
      "Sensitivity is equal to 0.9144736842105263\n",
      "Specificity is equal to 0.54421768707483\n",
      "Iteration 12 done\n",
      "Training accuracy is equal to 0.7330543994903564\n",
      "Test accuracy is equal to 0.7190635451505016\n",
      "Sensitivity is equal to 0.9210526315789473\n",
      "Specificity is equal to 0.5102040816326531\n",
      "Iteration 13 done\n",
      "Training accuracy is equal to 0.7414225935935974\n",
      "Test accuracy is equal to 0.7357859531772575\n",
      "Sensitivity is equal to 0.9210526315789473\n",
      "Specificity is equal to 0.54421768707483\n",
      "Iteration 14 done\n",
      "Training accuracy is equal to 0.7472803592681885\n",
      "Test accuracy is equal to 0.7491638795986622\n",
      "Sensitivity is equal to 0.9013157894736842\n",
      "Specificity is equal to 0.5918367346938775\n",
      "Iteration 15 done\n",
      "Training accuracy is equal to 0.7564853429794312\n",
      "Test accuracy is equal to 0.7491638795986622\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.6462585034013606\n",
      "Iteration 16 done\n",
      "Training accuracy is equal to 0.7656903862953186\n",
      "Test accuracy is equal to 0.7324414715719063\n",
      "Sensitivity is equal to 0.756578947368421\n",
      "Specificity is equal to 0.7074829931972789\n",
      "Iteration 17 done\n",
      "Training accuracy is equal to 0.7581589818000793\n",
      "Test accuracy is equal to 0.7290969899665551\n",
      "Sensitivity is equal to 0.7105263157894737\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 18 done\n",
      "Training accuracy is equal to 0.7556485533714294\n",
      "Test accuracy is equal to 0.725752508361204\n",
      "Sensitivity is equal to 0.6973684210526315\n",
      "Specificity is equal to 0.7551020408163265\n",
      "Iteration 19 done\n",
      "Training accuracy is equal to 0.7573221921920776\n",
      "Test accuracy is equal to 0.7424749163879598\n",
      "Sensitivity is equal to 0.743421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 20 done\n",
      "Training accuracy is equal to 0.7715480923652649\n",
      "Test accuracy is equal to 0.7625418060200669\n",
      "Sensitivity is equal to 0.8092105263157895\n",
      "Specificity is equal to 0.7142857142857143\n",
      "Iteration 21 done\n",
      "Training accuracy is equal to 0.7866109013557434\n",
      "Test accuracy is equal to 0.7658862876254181\n",
      "Sensitivity is equal to 0.8223684210526315\n",
      "Specificity is equal to 0.7074829931972789\n",
      "Iteration 22 done\n",
      "Training accuracy is equal to 0.7924686074256897\n",
      "Test accuracy is equal to 0.7558528428093646\n",
      "Sensitivity is equal to 0.8289473684210527\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 23 done\n",
      "Training accuracy is equal to 0.7949790954589844\n",
      "Test accuracy is equal to 0.7625418060200669\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 24 done\n",
      "Training accuracy is equal to 0.7991631627082825\n",
      "Test accuracy is equal to 0.782608695652174\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 25 done\n",
      "Training accuracy is equal to 0.8033472895622253\n",
      "Test accuracy is equal to 0.782608695652174\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 26 done\n",
      "Training accuracy is equal to 0.800000011920929\n",
      "Test accuracy is equal to 0.782608695652174\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 27 done\n",
      "Training accuracy is equal to 0.8075313568115234\n",
      "Test accuracy is equal to 0.782608695652174\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6802721088435374\n",
      "Iteration 28 done\n",
      "Training accuracy is equal to 0.8092049956321716\n",
      "Test accuracy is equal to 0.7859531772575251\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6870748299319728\n",
      "Iteration 29 done\n",
      "Training accuracy is equal to 0.8100418448448181\n",
      "Test accuracy is equal to 0.7859531772575251\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.6870748299319728\n",
      "Iteration 30 done\n",
      "Training accuracy is equal to 0.8150627613067627\n",
      "Test accuracy is equal to 0.7859531772575251\n",
      "Sensitivity is equal to 0.875\n",
      "Specificity is equal to 0.6938775510204082\n",
      "Iteration 31 done\n",
      "Training accuracy is equal to 0.8150627613067627\n",
      "Test accuracy is equal to 0.7892976588628763\n",
      "Sensitivity is equal to 0.875\n",
      "Specificity is equal to 0.7006802721088435\n",
      "Iteration 32 done\n",
      "Training accuracy is equal to 0.8209205269813538\n",
      "Test accuracy is equal to 0.7993311036789298\n",
      "Sensitivity is equal to 0.875\n",
      "Specificity is equal to 0.7210884353741497\n",
      "Iteration 33 done\n",
      "Training accuracy is equal to 0.8184100389480591\n",
      "Test accuracy is equal to 0.7959866220735786\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7278911564625851\n",
      "Iteration 34 done\n",
      "Training accuracy is equal to 0.8167364001274109\n",
      "Test accuracy is equal to 0.7959866220735786\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7278911564625851\n",
      "Iteration 35 done\n",
      "Training accuracy is equal to 0.812552273273468\n",
      "Test accuracy is equal to 0.7993311036789298\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7278911564625851\n",
      "Iteration 36 done\n",
      "Training accuracy is equal to 0.8158996105194092\n",
      "Test accuracy is equal to 0.7993311036789298\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7278911564625851\n",
      "Iteration 37 done\n",
      "Training accuracy is equal to 0.8175732493400574\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 38 done\n",
      "Training accuracy is equal to 0.8175732493400574\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 39 done\n",
      "Training accuracy is equal to 0.8175732493400574\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 40 done\n",
      "Training accuracy is equal to 0.8167364001274109\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 41 done\n",
      "Training accuracy is equal to 0.8184100389480591\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.7346938775510204\n",
      "Iteration 42 done\n",
      "Training accuracy is equal to 0.8217573165893555\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.881578947368421\n",
      "Specificity is equal to 0.7346938775510204\n",
      "Iteration 43 done\n",
      "Training accuracy is equal to 0.8251045942306519\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.875\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 44 done\n",
      "Training accuracy is equal to 0.8267782330513\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 45 done\n",
      "Training accuracy is equal to 0.8276150822639465\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7346938775510204\n",
      "Iteration 46 done\n",
      "Training accuracy is equal to 0.8276150822639465\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 47 done\n",
      "Training accuracy is equal to 0.8301255106925964\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 48 done\n",
      "Training accuracy is equal to 0.8292887210845947\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 49 done\n",
      "Training accuracy is equal to 0.8292887210845947\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 50 done\n",
      "Training accuracy is equal to 0.8326359987258911\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 51 done\n",
      "Training accuracy is equal to 0.8326359987258911\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7414965986394558\n",
      "Iteration 52 done\n",
      "Training accuracy is equal to 0.8368200659751892\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 53 done\n",
      "Training accuracy is equal to 0.8376569151878357\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 54 done\n",
      "Training accuracy is equal to 0.8401673436164856\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 55 done\n",
      "Training accuracy is equal to 0.843514621257782\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 56 done\n",
      "Training accuracy is equal to 0.8418409824371338\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 57 done\n",
      "Training accuracy is equal to 0.8426778316497803\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 58 done\n",
      "Training accuracy is equal to 0.8451882600784302\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 59 done\n",
      "Training accuracy is equal to 0.8468618988990784\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 60 done\n",
      "Training accuracy is equal to 0.8460251092910767\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 61 done\n",
      "Training accuracy is equal to 0.849372386932373\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7482993197278912\n",
      "Iteration 62 done\n",
      "Training accuracy is equal to 0.8527196645736694\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7551020408163265\n",
      "Iteration 63 done\n",
      "Training accuracy is equal to 0.8543933033943176\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7619047619047619\n",
      "Iteration 64 done\n",
      "Training accuracy is equal to 0.8560669422149658\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7619047619047619\n",
      "Iteration 65 done\n",
      "Training accuracy is equal to 0.8569037914276123\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 66 done\n",
      "Training accuracy is equal to 0.8560669422149658\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 67 done\n",
      "Training accuracy is equal to 0.857740581035614\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 68 done\n",
      "Training accuracy is equal to 0.8594142198562622\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 69 done\n",
      "Training accuracy is equal to 0.8602510690689087\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 70 done\n",
      "Training accuracy is equal to 0.8627614974975586\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 71 done\n",
      "Training accuracy is equal to 0.866108775138855\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 72 done\n",
      "Training accuracy is equal to 0.866108775138855\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7619047619047619\n",
      "Iteration 73 done\n",
      "Training accuracy is equal to 0.8644351363182068\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 74 done\n",
      "Training accuracy is equal to 0.8669456243515015\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7687074829931972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 75 done\n",
      "Training accuracy is equal to 0.871966540813446\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 76 done\n",
      "Training accuracy is equal to 0.8736401796340942\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 77 done\n",
      "Training accuracy is equal to 0.874476969242096\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 78 done\n",
      "Training accuracy is equal to 0.8778242468833923\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 79 done\n",
      "Training accuracy is equal to 0.8786610960960388\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 80 done\n",
      "Training accuracy is equal to 0.8786610960960388\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 81 done\n",
      "Training accuracy is equal to 0.880334734916687\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 82 done\n",
      "Training accuracy is equal to 0.8811715245246887\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 83 done\n",
      "Training accuracy is equal to 0.880334734916687\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 84 done\n",
      "Training accuracy is equal to 0.8811715245246887\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 85 done\n",
      "Training accuracy is equal to 0.8828451633453369\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 86 done\n",
      "Training accuracy is equal to 0.8853556513786316\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 87 done\n",
      "Training accuracy is equal to 0.8861924409866333\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 88 done\n",
      "Training accuracy is equal to 0.888702929019928\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8289473684210527\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 89 done\n",
      "Training accuracy is equal to 0.8895397782325745\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8289473684210527\n",
      "Specificity is equal to 0.782312925170068\n",
      "Iteration 90 done\n",
      "Training accuracy is equal to 0.8912134170532227\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8289473684210527\n",
      "Specificity is equal to 0.782312925170068\n",
      "Iteration 91 done\n",
      "Training accuracy is equal to 0.8920502066612244\n",
      "Test accuracy is equal to 0.802675585284281\n",
      "Sensitivity is equal to 0.8289473684210527\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 92 done\n",
      "Training accuracy is equal to 0.8937238454818726\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 93 done\n",
      "Training accuracy is equal to 0.894560694694519\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 94 done\n",
      "Training accuracy is equal to 0.9004184007644653\n",
      "Test accuracy is equal to 0.8060200668896321\n",
      "Sensitivity is equal to 0.8355263157894737\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 95 done\n",
      "Training accuracy is equal to 0.9012552499771118\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 96 done\n",
      "Training accuracy is equal to 0.9004184007644653\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 97 done\n",
      "Training accuracy is equal to 0.9004184007644653\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 98 done\n",
      "Training accuracy is equal to 0.9037656784057617\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 99 done\n",
      "Training accuracy is equal to 0.9020920395851135\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 100 done\n",
      "Training accuracy is equal to 0.9071129560470581\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 101 done\n",
      "Training accuracy is equal to 0.9071129560470581\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 102 done\n",
      "Training accuracy is equal to 0.9079498052597046\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 103 done\n",
      "Training accuracy is equal to 0.911297082901001\n",
      "Test accuracy is equal to 0.8093645484949833\n",
      "Sensitivity is equal to 0.8421052631578947\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 104 done\n",
      "Training accuracy is equal to 0.9138075113296509\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 105 done\n",
      "Training accuracy is equal to 0.9129707217216492\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 106 done\n",
      "Training accuracy is equal to 0.9138075113296509\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 107 done\n",
      "Training accuracy is equal to 0.9154811501502991\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 108 done\n",
      "Training accuracy is equal to 0.9171547889709473\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 109 done\n",
      "Training accuracy is equal to 0.9171547889709473\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 110 done\n",
      "Training accuracy is equal to 0.9171547889709473\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 111 done\n",
      "Training accuracy is equal to 0.9188284277915955\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 112 done\n",
      "Training accuracy is equal to 0.92384934425354\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 113 done\n",
      "Training accuracy is equal to 0.9246861934661865\n",
      "Test accuracy is equal to 0.8193979933110368\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7687074829931972\n",
      "Iteration 114 done\n",
      "Training accuracy is equal to 0.9255229830741882\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 115 done\n",
      "Training accuracy is equal to 0.9255229830741882\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.868421052631579\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 116 done\n",
      "Training accuracy is equal to 0.9263598322868347\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 117 done\n",
      "Training accuracy is equal to 0.9271966814994812\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 118 done\n",
      "Training accuracy is equal to 0.9271966814994812\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 119 done\n",
      "Training accuracy is equal to 0.9271966814994812\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 120 done\n",
      "Training accuracy is equal to 0.9263598322868347\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 121 done\n",
      "Training accuracy is equal to 0.9280334711074829\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 122 done\n",
      "Training accuracy is equal to 0.9280334711074829\n",
      "Test accuracy is equal to 0.8127090301003345\n",
      "Sensitivity is equal to 0.8486842105263158\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 123 done\n",
      "Training accuracy is equal to 0.9297071099281311\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 124 done\n",
      "Training accuracy is equal to 0.9297071099281311\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 125 done\n",
      "Training accuracy is equal to 0.9305439591407776\n",
      "Test accuracy is equal to 0.8160535117056856\n",
      "Sensitivity is equal to 0.8552631578947368\n",
      "Specificity is equal to 0.7755102040816326\n",
      "Iteration 126 done\n",
      "Training accuracy is equal to 0.9322175979614258\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.782312925170068\n",
      "Iteration 127 done\n",
      "Training accuracy is equal to 0.933891236782074\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.782312925170068\n",
      "Iteration 128 done\n",
      "Training accuracy is equal to 0.9347280263900757\n",
      "Test accuracy is equal to 0.822742474916388\n",
      "Sensitivity is equal to 0.8618421052631579\n",
      "Specificity is equal to 0.782312925170068\n"
     ]
    }
   ],
   "source": [
    "iters = 128\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(max_len, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=.01)\n",
    "\n",
    "loss_history = [] #Per iteration\n",
    "accuracy_history = []\n",
    "accuracy_test_history = []\n",
    "sensitivity_history = [] # True positive rate\n",
    "specificity_history = [] # True negative rate\n",
    "\n",
    "for i in range(iters): # Each iteration is on the full dataset here\n",
    "    proba_pred = net(X_train)  # forward pass\n",
    "    proba_pred = proba_pred.squeeze(-1)  # transform the 1-element vectors into scalars\n",
    "\n",
    "    optimizer.zero_grad() # reset the gradients to 0\n",
    "    loss = criterion(proba_pred, Y_train)\n",
    "    loss_history.append(loss.item()) # .item() to turn it into a python number\n",
    "    loss.backward()  # obtain the gradients with respect to the loss\n",
    "    optimizer.step()  # perform one step of gradient descent\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y_pred = proba_pred > 0.5  # Binary label\n",
    "        accuracy = (Y_train == Y_pred).float().mean()\n",
    "        accuracy_history.append(accuracy.item())\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        proba_pred_test = net(X_test)\n",
    "        proba_pred_test = proba_pred_test.squeeze(-1)\n",
    "        Y_pred_test = proba_pred_test > 0.5\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred_test).ravel()\n",
    "        accuracy_test_history.append((tn+tp)/(tn+fp+fn+tp))\n",
    "        sensitivity_history.append(tp/(tp+fn))\n",
    "        specificity_history.append(tn/(tn+fp))\n",
    "    \n",
    "    print(\"Iteration {iter} done\".format(iter=i+1))\n",
    "    print(\"Training accuracy is equal to {trainAcc}\".format(trainAcc=accuracy_history[-1]))\n",
    "    print(\"Test accuracy is equal to {t}\".format(t=accuracy_test_history[-1]))\n",
    "    print(\"Sensitivity is equal to {t}\".format(t=sensitivity_history[-1]))\n",
    "    print(\"Specificity is equal to {t}\".format(t=specificity_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae18811dc0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae1892de20>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_history)\n",
    "plt.plot(accuracy_test_history) # It doesn't really get better on test set than 75%,\n",
    "                                # close to 80% before the end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ae1899ad60>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sensitivity_history)\n",
    "plt.plot(specificity_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of results of MLP\n",
    "As excepted, the MLP naive solution caps out very quickly at 75% accuracy, which is not terrible but far from being good. There are two main problems with the current architecture :\n",
    "1. Our method of turning words into numbers doesn't have any spatial relationship : words that are close to each other in the number domain have no reason to be related to one another for the purpose of detecting spam.\n",
    "2. The MLP architecture has no inductive bias to work with sequences of words.\n",
    "\n",
    "There are also minor problems that are worth addressing\n",
    "1. We discarded many observations to obtain a balanced dataset, but there are better ways to handle this. We could look into *upsampling*, or changing the way we evaluate the model so that the unbalance doesn't favor guessing \"ham\".\n",
    "2. Our tokenizer has a vocabulary size of 500 but we have more than 4000 words, which means many rare words are converted into the same token. On top of that, we truncate sentences that are longer than 50 words. **Those are general problems with the naive word embedding**, the solution is to use another method altogether, not to solve those problems one at a time.\n",
    "\n",
    "On the bright side,  training this model is very quick and the dataset is lightweight, which means we can load all of it at the same time if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
